%% plot learning rate - F1-score

% Logistic Regression

training = [0.114381833474;
0.923965351299;
0.951566951567;
0.965192850423;
0.969014084507;
0.970946579194;
0.972820993440;
0.973782771536;
0.974742750234;
0.975655430712;
0.978403755869;
0.978403755869;
0.978403755869;
0.978403755869;
0.978403755869;
0.978403755869;
0.978403755869;
0.978403755869;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271];

testing = [0.034285714286;
0.919540229885;
0.965517241379;
0.971428571429;
0.971428571429;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458;
0.983050847458];

figure
subplot(2,1,1)
title('Logistic Regression')
ylabel('F1 - score')
xlabel('epoch')
grid on
hold on
plot(training, 'o-')
plot(testing, 'o-')
legend('training','testing')
ylim([.7, 1])

% NN

training = [nan;
nan;
nan;
nan;
0.794672586016;
0.893069306931;
0.934761441091;
0.955534531693;
0.968045112782;
0.970892018779;
0.973782771536;
0.975655430712;
0.978403755869;
0.978403755869;
0.978403755869;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.979323308271;
0.983018867925;
0.983018867925;
0.983018867925;
0.983018867925;
0.983018867925;
0.983018867925;
0.983018867925;
0.983018867925;
0.983018867925;
0.983018867925;
0.983018867925;
0.985808893094;
0.985808893094;
0.985808893094;
0.985808893094;
0.990494296578;
0.990494296578;
0.990494296578;
0.990494296578;
0.990494296578;
0.990494296578;
0.990494296578;
0.990494296578;
0.990494296578];

testing = [nan;
nan;
nan;
nan;
0.738255033557;
0.906976744186;
0.941176470588;
0.965517241379;
0.971428571429;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.977272727273;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857;
0.982857142857];

subplot(2,1,2)
title('Neural Network')
ylabel('F1 - score')
xlabel('epoch')
grid on
hold on
plot(training, 'o-')
plot(testing, 'o-')
legend('training','testing')